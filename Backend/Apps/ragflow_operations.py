import requests
import time
import os
from config import ragflow_BASE_URL,ragflow_API_KEY


HEADERS = {
    "Authorization": f"Bearer {ragflow_API_KEY}",
    "Content-Type": "application/json"
}


def create_dataset(name: str, description: str = "") -> str:
    """
    åˆ›å»ºæ•°æ®é›†ï¼Œè¿”å› dataset_id
    å‚æ•°:
        name: æ•°æ®é›†åç§°
        description: æ•°æ®é›†æè¿°
    """
    timestamp = int(time.time())
    unique_name = f"{name}_{timestamp}"

    url = f"{ragflow_BASE_URL}/api/v1/datasets"
    payload = {
        "name": unique_name,
        "description": description
    }

    response = requests.post(url, headers=HEADERS, json=payload)
    data = response.json()

    if data.get("code") == 0:
        dataset_id = data["data"]["id"]
        return dataset_id
    else:
        raise Exception(f"âŒ åˆ›å»ºæ•°æ®é›†å¤±è´¥: {data}")




def upload_and_parse_documents(dataset_id: str, file_paths: list) -> list:
    """
    æ‰¹é‡ä¸Šä¼ æ–‡æ¡£åˆ°æŒ‡å®šæ•°æ®é›†å¹¶è‡ªåŠ¨è§£æ

    å‚æ•°:
        dataset_id: æ•°æ®é›†ID
        file_paths: è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨

    è¿”å›:
        æ–‡æ¡£IDåˆ—è¡¨

    å¼‚å¸¸:
        å¦‚æœä¸Šä¼ æˆ–è§£æå¤±è´¥åˆ™æŠ›å‡ºå¼‚å¸¸
    """
    # 1. ä¸Šä¼ æ–‡æ¡£
    upload_url = f"{ragflow_BASE_URL}/api/v1/datasets/{dataset_id}/documents"
    document_ids = []

    try:
        for file_path in file_paths:
            with open(file_path, 'rb') as file:
                # ä½¿ç”¨fileså‚æ•°ä¸Šä¼ æ–‡ä»¶
                response = requests.post(
                    upload_url,
                    headers={"Authorization": f"Bearer {ragflow_API_KEY}"},
                    files={'file': (os.path.basename(file_path), file)}
                )

                if response.status_code != 200:
                    raise Exception(f"ä¸Šä¼ å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”: {response.text}")

                data = response.json()

                if data.get("code") != 0:
                    raise Exception(f"ä¸Šä¼ å¤±è´¥: {data}")

                document_id = data["data"][0]["id"]
                document_ids.append(document_id)
                print(f"âœ… æ–‡æ¡£ä¸Šä¼ æˆåŠŸ: {document_id}")

        # 2. è§¦å‘è§£æ
        parse_url = f"{ragflow_BASE_URL}/api/v1/datasets/{dataset_id}/chunks"
        parse_payload = {
            "document_ids": document_ids
        }

        parse_response = requests.post(parse_url, headers=HEADERS, json=parse_payload)
        parse_data = parse_response.json()

        if parse_data.get("code") != 0:
            raise Exception(f"è§£æè§¦å‘å¤±è´¥: {parse_data}")

        print("âœ… æ‰¹é‡æ–‡æ¡£è§£æå·²è§¦å‘")
        return document_ids

    except Exception as e:
        raise Exception(f"âŒ æ‰¹é‡ä¸Šä¼ å’Œè§£æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")



def get_file_paths(folder_path: str) -> list:
    """
    è·å–æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    å‚æ•°:
        folder_path: æ–‡ä»¶å¤¹è·¯å¾„
    è¿”å›:
        file_paths: åŒ…å«æ‰€æœ‰æ–‡ä»¶è·¯å¾„çš„åˆ—è¡¨
    """
    file_paths = []
    # éå†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶å’Œå­æ–‡ä»¶å¤¹
    for root, dirs, files in os.walk(folder_path):
        for file in files:
            # è·å–æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
            file_path = os.path.join(root, file)
            file_paths.append(file_path)

    return file_paths



# ç¤ºä¾‹ä½¿ç”¨ï¼š
if __name__ == "__main__":
    try:
        # 1. åˆ›å»ºæ•°æ®é›†
        dataset_id = create_dataset("æµ‹è¯•æ•°æ®é›†", "ä¸Šä¼ æ–‡æ¡£å¹¶è§£ææµ‹è¯•")

        # 2. ä¸Šä¼ å¹¶è§£ææ–‡æ¡£
        folder_path = "D:\projcet_LLM\EduPlatform\Backend\static\ragflowParserDocs"

        file_paths = get_file_paths(folder_path)
        document_id = upload_and_parse_documents(dataset_id, file_paths)

        print(f"ğŸ‰ æ“ä½œæˆåŠŸå®Œæˆï¼æ•°æ®é›†ID: {dataset_id}, æ–‡æ¡£ID: {document_id}")

    except Exception as e:
        print(f"âŒ æ“ä½œå¤±è´¥: {str(e)}")